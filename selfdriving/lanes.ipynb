{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import cv2 for breaking images down to pixels or continuous arrays\n",
    "img = cv2.imread('test_image.jpg')\n",
    "#It's imparative to make a copy of image, in\n",
    "lane_img = np.copy(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def canny(image):\n",
    "    #To convert the color of image from a RGB to grayscale\n",
    "    #cuz the number of channel of a RGB image is 3, whereas grayscale channel is 1,\n",
    "    #Thus grayscale image enables to run itself faster than RGB\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    #for reducing the noises of the image, we use GaussianBlur\n",
    "    #in which the algorhthm takes averages of the adjacent pixels and \n",
    "    #average them\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    #isolate the edge in images, we are using the derivative of the adjacent pixels\n",
    "    #thus we know the slope of specific points \n",
    "    #images are arrays of consective pixels, \n",
    "    # we can denote like this pixel = (x,y)\n",
    "    #if a griedient of the adjacent pixels is lower than lowest_thrushhold\n",
    "    #It'll be ingored \n",
    "    #if a griedient of the adjacent pixels is higher than highest_thrushhold\n",
    "    #It's gonna be itentified as an edge\n",
    "    #If a gredient of adjacent pixels is between lowest and highest_thrushhold\n",
    "    #It'll be identified as edges, only if it's placed next to the edges\n",
    "    #The documentation recommends to use the ratio of thrushholds 1:3\n",
    "    canny = cv2.Canny(blur,50,150)\n",
    "    return canny\n",
    "\n",
    "def region_of_interest(image):\n",
    "    #to limit our images for an extent where we can identify lanes\n",
    "    #first, we specify the area of images \n",
    "\n",
    "    #get the rows from image's shape\n",
    "    height = image.shape[0]\n",
    "    #specify the cordinates where you want to idetify objects\n",
    "    polygons = np.array([\n",
    "    [(200,height),(1100,height),(550,250)]\n",
    "    ])\n",
    "    #then make a copy of image in black, then mask with the polygon we made above\n",
    "    mask = np.zeros_like(image)\n",
    "    cv2.fillPoly(mask,polygons,255)\n",
    "    \n",
    "    #8 bit binary representation's maximum number that can show\n",
    "    # is 255. When a pixel is completely black, the binary representation\n",
    "    # should be 00000000. When we operate bitwise-and to the corresponding\n",
    "    # region of the other image, All of the pixels which are at same matrix\n",
    "    # will be all zero(0). Cause in bitwise-and 1 applied only if the bit value\n",
    "    # of two images are both 1, otherwise 0. \n",
    "    masked_image= cv2.bitwise_and(mask,image)\n",
    "    \n",
    "    # lines detection\n",
    "    # we detect lines in region of interest.\n",
    "    # lines are a series of dots. then to find the line's equasion by using \n",
    "    # hough line, which detects intersections --with params (radians,distance)\n",
    "    # the line pass through the dots/points \n",
    "    # divided houghline to bins, then take the most intersections including bin\n",
    "    # the params in that bin tends to pass  \n",
    "    lines = cv2.HoughLinesP(masked_image,2,np.pi/180,100,np.array([]),minLineLength = 40, maxLineGap =5)\n",
    "    return masked_image,lines\n",
    "\n",
    "def lines_onto_black_image(image,lines):\n",
    "    #create completely black image with the same dimention as image\n",
    "    lines_onto_black_image = np.zeros_like(image)\n",
    "    #just confirm that we detected the lines with houghlinep\n",
    "    if lines is not None:\n",
    "        for l in lines:\n",
    "            # raw coordinates are 3 dimentional array like below\n",
    "                #[[[,,,,]]\n",
    "                # [[,,,,]]\n",
    "                # ]\n",
    "            # in for loop these convert to 2 dimentions\n",
    "            # then we wanna use 1 dimention, 4 coordinates then reshape\n",
    "            x1,y1,x2,y2 = l.reshape(4)\n",
    "            # after that cv2.line allows us to draw lines between 2 points (x1,y1),(x2,y2)\n",
    "            cv2.line(lines_onto_black_image,(x1,y1),(x2,y2),(255,0,0),10)\n",
    "        return lines_onto_black_image\n",
    "    \n",
    "def average_slope_intercept(image,lines):\n",
    "    # for smoothing the lines\n",
    "    # average slope and intercept\n",
    "    left_line = []\n",
    "    right_line = []\n",
    "    \n",
    "    for l in lines:\n",
    "        x1,y1,x2,y2 = l.reshape(4)\n",
    "        #polyfit returns first degree polynomial's coefficients\n",
    "        #but depending on argument of deg(degree)\n",
    "        #first degree means the equation with 1 exponential\n",
    "        paramators = np.polyfit((x1,x2),(y1,y2),1)\n",
    "        slope = paramators[0]\n",
    "        intercepts = paramators[1]\n",
    "    \n",
    "    #as for this image, two lines slanted to the right, and left respectively\n",
    "    #y axis of image from the top of left side downward to the bottum of left\n",
    "    #so the slope of the line slanted to the right is negative\n",
    "    #the slope of the line slanted to the left is positive\n",
    "        if slope < 0:\n",
    "            left_line.append((slope, intercepts))\n",
    "        else:\n",
    "            right_line.append((slope, intercepts))\n",
    "    #then average out each slope and intercepts respectively\n",
    "    left_line_average = np.average(left_line,axis=0)\n",
    "    right_line_average = np.average(right_line,axis=0)\n",
    "    ave_left_line = get_coordinates(image,left_line_average)\n",
    "    ave_right_line = get_coordinates(image,right_line_average)\n",
    "    #[308 704 483 422] [978 704 703 422]\n",
    "    #as seen above, returned values are the coordinates of each line--left/right\n",
    "    return ave_left_line, ave_right_line\n",
    "    \n",
    "def get_coordinates(image,line_params):\n",
    "    slope, intercepts = line_params\n",
    "    y1 = image.shape[0]\n",
    "    y2 = int(y1*3/5)\n",
    "    x1 = int((y1-intercepts)/slope)\n",
    "    x2 = int((y2-intercepts)/slope)\n",
    "    return np.array([x1,y1,x2,y2])\n",
    "\n",
    "# canny = canny(lane_img)\n",
    "\n",
    "# masked_image,lines = region_of_interest(canny)\n",
    "# averaged_lines = average_slope_intercept(lane_image,lines)\n",
    "# lines_onto_black_image = lines_onto_black_image(lane_img,averaged_lines)\n",
    "# #blend the first lane_image and the lines_image\n",
    "# #in lines_image whole region is black other than lines \n",
    "# #it means pixels intensities equal to 0\n",
    "# #therefore adding pixels intensities of black space won't make\n",
    "# #any differences, only when add the intensities of lines we can cee\n",
    "# #them on raw images\n",
    "# blended_image = cv2.addWeighted(lane_img,0.8, lines_onto_black_image,1,1)\n",
    "\n",
    "# cv2.imshow('lanes',blended_image )\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\matrix.cpp:246: error: (-215:Assertion failed) s >= 0 in function 'cv::setSize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ryona\\learning\\selfdriving\\lanes.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ryona/learning/selfdriving/lanes.ipynb#ch0000003?line=6'>7</a>\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ryona/learning/selfdriving/lanes.ipynb#ch0000003?line=7'>8</a>\u001b[0m     \u001b[39m# then detect lines and project it on video frame/image\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ryona/learning/selfdriving/lanes.ipynb#ch0000003?line=8'>9</a>\u001b[0m     \u001b[39m# Just changed the input image from lane_image to frame\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ryona/learning/selfdriving/lanes.ipynb#ch0000003?line=9'>10</a>\u001b[0m     canny \u001b[39m=\u001b[39m canny[frame]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ryona/learning/selfdriving/lanes.ipynb#ch0000003?line=11'>12</a>\u001b[0m     masked_image,lines \u001b[39m=\u001b[39m region_of_interest(canny)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ryona/learning/selfdriving/lanes.ipynb#ch0000003?line=12'>13</a>\u001b[0m     averaged_lines \u001b[39m=\u001b[39m average_slope_intercept(frame,lines)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ryona/learning/selfdriving/lanes.ipynb#ch0000003?line=13'>14</a>\u001b[0m     lines_onto_black_image \u001b[39m=\u001b[39m lines_onto_black_image(frame,averaged_lines)\n",
      "\u001b[1;32mc:\\Users\\ryona\\learning\\selfdriving\\lanes.ipynb Cell 4\u001b[0m in \u001b[0;36mregion_of_interest\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ryona/learning/selfdriving/lanes.ipynb#ch0000003?line=43'>44</a>\u001b[0m masked_image\u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mbitwise_and(mask,image)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ryona/learning/selfdriving/lanes.ipynb#ch0000003?line=45'>46</a>\u001b[0m \u001b[39m# lines detection\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ryona/learning/selfdriving/lanes.ipynb#ch0000003?line=46'>47</a>\u001b[0m \u001b[39m# we detect lines in region of interest.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ryona/learning/selfdriving/lanes.ipynb#ch0000003?line=47'>48</a>\u001b[0m \u001b[39m# lines are a series of dots. then to find the line's equasion by using \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ryona/learning/selfdriving/lanes.ipynb#ch0000003?line=50'>51</a>\u001b[0m \u001b[39m# divided houghline to bins, then take the most intersections including bin\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ryona/learning/selfdriving/lanes.ipynb#ch0000003?line=51'>52</a>\u001b[0m \u001b[39m# the params in that bin tends to pass  \u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ryona/learning/selfdriving/lanes.ipynb#ch0000003?line=52'>53</a>\u001b[0m lines \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mHoughLinesP(masked_image,\u001b[39m2\u001b[39;49m,np\u001b[39m.\u001b[39;49mpi\u001b[39m/\u001b[39;49m\u001b[39m180\u001b[39;49m,\u001b[39m100\u001b[39;49m,np\u001b[39m.\u001b[39;49marray([]),minLineLength \u001b[39m=\u001b[39;49m \u001b[39m40\u001b[39;49m, maxLineGap \u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ryona/learning/selfdriving/lanes.ipynb#ch0000003?line=53'>54</a>\u001b[0m \u001b[39mreturn\u001b[39;00m masked_image,lines\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\matrix.cpp:246: error: (-215:Assertion failed) s >= 0 in function 'cv::setSize'\n"
     ]
    }
   ],
   "source": [
    "#video line detection \n",
    "#capture the video, and while it's run as each single frame\n",
    "#detect and get 2 values(boolean, frame)\n",
    "cap = cv2.VideoCapture('test2.mp4')\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        # then detect lines and project it on video frame/image\n",
    "        # Just changed the input image from lane_image to frame\n",
    "        canny = canny(frame)\n",
    "\n",
    "        masked_image,lines = region_of_interest(canny)\n",
    "        averaged_lines = average_slope_intercept(frame,lines)\n",
    "        lines_onto_black_image = lines_onto_black_image(frame,averaged_lines)\n",
    "        #blend the first lane_image and the lines_image\n",
    "        #in lines_image whole region is black other than lines \n",
    "        #it means pixels intensities equal to 0\n",
    "        #therefore adding pixels intensities of black space won't make\n",
    "        #any differences, only when add the intensities of lines we can cee\n",
    "        #them on raw images\n",
    "        blended_image = cv2.addWeighted(frame,0.8, lines_onto_black_image,1,1)\n",
    "\n",
    "        cv2.imshow('lanes',blended_image )\n",
    "    # Press Q on keyboard to  exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "  # Break the loop\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# When everything done, release the video capture object\n",
    "\n",
    "cap.release()\n",
    "# Closes all the frames\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('driving': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71896b83fb11a20e0bdba9d1ee773c5cd354f455a6d9eb99f2ec9fd0303bdaa1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
